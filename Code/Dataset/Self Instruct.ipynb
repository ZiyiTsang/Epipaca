{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-25T10:31:13.739610Z",
     "start_time": "2024-05-25T10:31:09.816399Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "# from Utils import utils\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "project_path = os.path.abspath(os.path.relpath('../../../', os.getcwd()))\n",
    "data_path = os.path.join(project_path, 'FT4LLM/Data')\n",
    "prompt_path = os.path.join(data_path, 'prompt')\n",
    "\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "import  numpy as np\n",
    "\n",
    "num_prompt_instructions = 5\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "scorer = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=False)"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:31:13.787154Z",
     "start_time": "2024-05-25T10:31:13.743617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "if os.path.exists(data_path + \"/machine_instructions.json\"):\n",
    "    machine_data_df = pd.read_json(data_path + \"/machine_instructions.json\")\n",
    "    print(f\"Loaded {len(machine_data_df)} GPT-written seed instructions\")\n",
    "else:\n",
    "    print(\"Create new bank for machine_instructions\")\n",
    "    machine_data_df = pd.DataFrame()\n",
    "\n",
    "seed_tasks = [json.loads(l.strip().rstrip(',')) for l in open(data_path + \"/seed_tasks_seizure.jsonl\", \"r\")]\n",
    "seed_instruction_data = [\n",
    "    {\"instruction\": t[\"instruction\"], \"input\": t[\"instances\"][0][\"input\"], \"output\": t[\"instances\"][0][\"output\"]}\n",
    "    for t in seed_tasks\n",
    "]\n",
    "print(f\"Loaded {len(seed_instruction_data)} human-written seed instructions\")\n",
    "\n"
   ],
   "id": "484dfecc7b8c0a95",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:31:13.803150Z",
     "start_time": "2024-05-25T10:31:13.790162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_bank_token():\n",
    "    all_instructions = [d[\"instruction\"] for d in seed_instruction_data] + machine_data_df['instruction'].to_list()\n",
    "    _all_instruction_tokens = [scorer._tokenizer.tokenize(inst) for inst in all_instructions]\n",
    "    return _all_instruction_tokens\n"
   ],
   "id": "a73ef0f6f1b6084d",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:31:13.835160Z",
     "start_time": "2024-05-25T10:31:13.806159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def encode_prompt(prompt_instructions, file_name):\n",
    "    \"\"\"Encode multiple prompt instructions into a single string.\"\"\"\n",
    "    prompt = open(prompt_path + file_name).read() + \"\\n\"\n",
    "\n",
    "    for idx, task_dict in enumerate(prompt_instructions):\n",
    "        (instruction, input, output) = task_dict[\"instruction\"], task_dict[\"input\"], task_dict[\"output\"]\n",
    "        instruction = re.sub(r\"\\s+\", \" \", instruction).strip().rstrip(\":\")\n",
    "        input = \"<noinput>\" if input.lower() == \"\" else input\n",
    "        prompt += f\"***\\n\"\n",
    "        prompt += f\"Instruction: {instruction}\\n\"\n",
    "        prompt += f\"Input:{input}\\n\"\n",
    "        prompt += f\"Output:{output}\\n\"\n",
    "    prompt += f\"***\\n\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def encode_prompt_knowledge():\n",
    "    with open(data_path + '/knowledge.txt', 'r', encoding='utf-8') as file:\n",
    "        knowledge = file.read()\n",
    "    with open(prompt_path + '/prompt_for_knowledge_first.txt', 'r', encoding='utf-8') as file:\n",
    "        prompt_knowledge = file.read()\n",
    "    prompt_knowledge = prompt_knowledge + knowledge\n",
    "    return prompt_knowledge\n",
    "\n",
    "\n",
    "def find_word_in_string(w, s):\n",
    "    return re.compile(r\"\\b({0})\\b\".format(w), flags=re.IGNORECASE).search(s)\n",
    "\n",
    "\n",
    "def process_response(raw_instructions, statistic_report):\n",
    "    instructions = []\n",
    "    input_texts = []\n",
    "    outputs = []\n",
    "    for i, inst in enumerate(raw_instructions):\n",
    "        inst = inst.strip()\n",
    "        if inst.startswith(\"Here is\"):\n",
    "            continue\n",
    "        statistic_report['Generate in beginning'] += 1\n",
    "        if len(inst.split()) <= 3 or len(inst.split()) > 150:\n",
    "            continue\n",
    "        blacklist = [\n",
    "            \"image\",\n",
    "            \"images\",\n",
    "            \"graph\",\n",
    "            \"graphs\",\n",
    "            \"picture\",\n",
    "            \"pictures\",\n",
    "            \"file\",\n",
    "            \"files\",\n",
    "            \"map\",\n",
    "            \"maps\",\n",
    "            \"draw\",\n",
    "            \"plot\",\n",
    "            \"go to\",\n",
    "            \"video\",\n",
    "            \"audio\",\n",
    "            \"music\",\n",
    "            \"flowchart\",\n",
    "            \"diagram\",\n",
    "            'code',\n",
    "            'program'\n",
    "        ]\n",
    "        if any(find_word_in_string(word, inst) for word in blacklist):\n",
    "            print(\"filter instruction bacause of blacklist\",end='')\n",
    "            continue\n",
    "        instruction_match = re.search(r'Instruction:(.+)', inst)\n",
    "        input_match = re.search(r'Input:(.+)', inst)\n",
    "        output_match = re.search(r'Output:(.+)', inst)\n",
    "\n",
    "        if instruction_match and input_match and output_match:\n",
    "            instruction = instruction_match.group(1).strip()\n",
    "            input_text = input_match.group(1).strip()\n",
    "            output_text = output_match.group(1).strip()\n",
    "            if input_text.startswith(\"<\") and input_text != \"<noinput>\":\n",
    "                print(\"filter instruction bacause of input\",end=None)\n",
    "                continue\n",
    "            if \"e.g.\" in input_text or \"this\" in input_text:\n",
    "                print(\"filter instruction bacause of input\",end=None)\n",
    "                continue\n",
    "            input_text = \"\" if input_text.lower() == \"<noinput>\" else input_text\n",
    "            if not instruction[0].isascii():\n",
    "                print(\"filter instruction bacause of languadge\",end=None)\n",
    "                continue\n",
    "            statistic_report['Keep in blocklist and formatting'] += 1\n",
    "            instructions.append(instruction)\n",
    "            input_texts.append(input_text)\n",
    "            outputs.append(output_text)\n",
    "\n",
    "    return {\"instruction\": instructions, \"input_word\": input_texts, \"output\": outputs}\n",
    "\n",
    "\n",
    "def remove_instruction_scoreler_base(all_instruction_tokens, new_instructions, statistic_report):\n",
    "    instructions_keeped = []\n",
    "    for row_index in range(new_instructions.shape[0]):\n",
    "        specific_ins = new_instructions.loc[row_index, \"instruction\"]\n",
    "        new_instruction_tokens = scorer._tokenizer.tokenize(specific_ins)\n",
    "        with Pool(8) as p:\n",
    "            rouge_scores = p.map(\n",
    "                partial(rouge_scorer._score_lcs, new_instruction_tokens),\n",
    "                all_instruction_tokens,\n",
    "            )\n",
    "        rouge_scores = [score.fmeasure for score in rouge_scores]\n",
    "        if max(rouge_scores) > 0.8:\n",
    "            continue\n",
    "        instructions_keeped.append(new_instructions.loc[row_index])\n",
    "        statistic_report[\"Keep in similar check\"] += 1\n",
    "    return pd.DataFrame(instructions_keeped)"
   ],
   "id": "95915ea1f6abd1f7",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:31:13.851154Z",
     "start_time": "2024-05-25T10:31:13.837156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n",
    "def getGenerateData_woutKnowledge(client,all_instruction_tokens):\n",
    "    statistic_report = {\"Keep in blocklist and formatting\": 0, \"Generate in beginning\": 0, \"Keep in similar check\": 0}\n",
    "    valid_instruction = []\n",
    "    for t in np.linspace(0.12, 0.6, 10):\n",
    "        for i in tqdm(range(int(len(seed_instruction_data) / num_prompt_instructions))):\n",
    "            prompt_instructions = random.sample(seed_instruction_data, num_prompt_instructions)\n",
    "            prompt = encode_prompt(prompt_instructions,'/prompt.txt')\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF\",\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=t,\n",
    "            )\n",
    "            response_text = completion.choices[0].message.content\n",
    "            raw_tasks = re.split(r\"\\*\\*\\*\", response_text)\n",
    "            raw_task_ = process_response(raw_tasks, statistic_report)\n",
    "            new_task_formated_df = pd.DataFrame({\n",
    "                \"instruction\": raw_task_['instruction'],\n",
    "                \"input_word\": raw_task_['input_word'],\n",
    "                \"output\": raw_task_['output']\n",
    "            })\n",
    "            similar_check_keep = remove_instruction_scoreler_base(all_instruction_tokens, new_task_formated_df,\n",
    "                                                                  statistic_report)\n",
    "            if similar_check_keep.shape[0] != 0:\n",
    "                valid_instruction.append(similar_check_keep)\n",
    "\n",
    "    print(statistic_report)\n",
    "    new_formated_data = pd.concat(valid_instruction)\n",
    "    return new_formated_data\n",
    "\n"
   ],
   "id": "90105f4615ea1e9b",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:31:49.166273Z",
     "start_time": "2024-05-25T10:31:17.563763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "instruction_tokens=get_bank_token()\n",
    "new_formated_data_woutKnowledge=getGenerateData_woutKnowledge(client,all_instruction_tokens=instruction_tokens)\n",
    "# machine_data_df=pd.concat([machine_data_df, new_formated_data_woutKnowledge], ignore_index=True)\n",
    "# "
   ],
   "id": "4cafaf0fad7ac9f6",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:18:34.366642Z",
     "start_time": "2024-05-25T10:18:34.345641Z"
    }
   },
   "cell_type": "code",
   "source": "machine_data_df",
   "id": "85990de5a4a09590",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Knowledge ",
   "id": "785a8d9680d3424e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T07:56:21.047902Z",
     "start_time": "2024-05-25T07:56:21.034907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def getGenerateData_wKnowledge(client,all_instruction_tokens):\n",
    "    statistic_report = {\"Keep in blocklist and formatting\": 0, \"Generate in beginning\": 0, \"Keep in similar check\": 0}\n",
    "    valid_instruction = []\n",
    "    prompt_knowledge = encode_prompt_knowledge()\n",
    "    prompt_instructions = random.sample(seed_instruction_data, num_prompt_instructions)\n",
    "    prompt_later = encode_prompt(prompt_instructions, '/prompt_for_knowledge_later.txt')\n",
    "    for t in np.linspace(0.10, 0.45, 8):\n",
    "        for _ in tqdm(range(int(len(seed_instruction_data) / num_prompt_instructions))):\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF\",\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt_knowledge},\n",
    "                    {\"role\": \"assistant\", \"content\": 'Ok'},\n",
    "                    {\"role\": \"user\", \"content\": prompt_later},\n",
    "                ],\n",
    "                temperature=t,\n",
    "            )\n",
    "            response_text = completion.choices[0].message.content\n",
    "            raw_tasks = re.split(r\"\\*\\*\\*\", response_text)\n",
    "            raw_task_ = process_response(raw_tasks, statistic_report)\n",
    "            new_task_formated_df = pd.DataFrame({\n",
    "                \"instruction\": raw_task_['instruction'],\n",
    "                \"input_word\": raw_task_['input_word'],\n",
    "                \"output\": raw_task_['output']\n",
    "            })\n",
    "            similar_check_keep = remove_instruction_scoreler_base(all_instruction_tokens, new_task_formated_df,\n",
    "                                                                  statistic_report)\n",
    "            if similar_check_keep.shape[0] != 0:\n",
    "                valid_instruction.append(similar_check_keep)\n",
    "        print(statistic_report)\n",
    "    new_formated_data = pd.concat(valid_instruction)\n",
    "    return new_formated_data"
   ],
   "id": "e14d9684f2617d67",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T07:58:32.230073Z",
     "start_time": "2024-05-25T07:56:22.789878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "instruction_tokens=get_bank_token()\n",
    "new_formated_data_wKnowledge=getGenerateData_wKnowledge(client,all_instruction_tokens=instruction_tokens)\n"
   ],
   "id": "996fbb057fa8bf0f",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T16:36:46.969926Z",
     "start_time": "2024-05-24T16:36:46.945520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "machine_data_df=pd.concat([machine_data_df, new_formated_data_wKnowledge], ignore_index=True)\n",
    "\n"
   ],
   "id": "a7e80d8ebbbe8c1b",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:20:35.420903Z",
     "start_time": "2024-05-25T10:20:35.407904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "empty_input_rows = machine_data_df[machine_data_df['input_word'].isnull() | (machine_data_df['input_word'] == '')]\n",
    "not_duplicate_rows=machine_data_df.drop_duplicates(subset=['input_word'], inplace=False)\n",
    "machine_data_df=pd.concat([empty_input_rows,not_duplicate_rows],ignore_index=True)\n",
    "machine_data_df.to_json(data_path + \"/machine_instructions.json\")"
   ],
   "id": "4705b4c8de9cb25c",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "3f7f7b2495f75258",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

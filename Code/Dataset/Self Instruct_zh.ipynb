{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-27T09:39:12.820507Z",
     "start_time": "2024-05-27T09:39:08.496889Z"
    }
   },
   "source": [
    "import logging\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "# from Utils import utils\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from rouge_chinese import Rouge\n",
    "import jieba\n",
    "\n",
    "project_path = os.path.abspath(os.path.relpath('../../../', os.getcwd()))\n",
    "data_path = os.path.join(project_path, 'FT4LLM/Data')\n",
    "prompt_path = os.path.join(data_path, 'prompt')\n",
    "\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "jieba.setLogLevel(logging.ERROR)\n",
    "\n",
    "num_prompt_instructions = 5\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T09:39:18.407418Z",
     "start_time": "2024-05-27T09:39:18.341420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "if os.path.exists(data_path + \"/machine_instructions_zh.json\"):\n",
    "    machine_data_df = pd.read_json(data_path + \"/machine_instructions_zh.json\")\n",
    "    print(f\"Loaded {len(machine_data_df)} GPT-written seed instructions\")\n",
    "else:\n",
    "    print(\"Create new bank for machine_instructions\")\n",
    "    machine_data_df = pd.DataFrame()\n",
    "\n",
    "seed_tasks = []\n",
    "with open(data_path + \"/seed_tasks_seizure_zh.jsonl\", \"r\", encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        stripped_line = line.strip().rstrip(',')\n",
    "        task = json.loads(stripped_line)\n",
    "        seed_tasks.append(task)\n",
    "\n",
    "seed_instruction_data = [\n",
    "    {\"instruction\": t[\"instruction\"], \"input\": t[\"instances\"][0][\"input\"], \"output\": t[\"instances\"][0][\"output\"]}\n",
    "    for t in seed_tasks\n",
    "]\n",
    "print(f\"Loaded {len(seed_instruction_data)} human-written seed instructions\")\n",
    "\n",
    "\n"
   ],
   "id": "484dfecc7b8c0a95",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T09:39:42.891405Z",
     "start_time": "2024-05-27T09:39:42.862189Z"
    }
   },
   "cell_type": "code",
   "source": "machine_data_df",
   "id": "76aa61cd2ff322b6",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:54:48.124730Z",
     "start_time": "2024-05-25T10:54:48.080731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n",
    "def encode_prompt(prompt_instructions, file_name):\n",
    "    \"\"\"Encode multiple prompt instructions into a single string.\"\"\"\n",
    "    prompt = open(prompt_path + file_name, 'r', encoding='utf-8').read() + \"\\n\"\n",
    "\n",
    "    for idx, task_dict in enumerate(prompt_instructions):\n",
    "        (instruction, input, output) = task_dict[\"instruction\"], task_dict[\"input\"], task_dict[\"output\"]\n",
    "        instruction = re.sub(r\"\\s+\", \" \", instruction).strip().rstrip(\":\")\n",
    "        input = \"<无>\" if input.lower() == \"\" else input\n",
    "        prompt += f\"###\\n\"\n",
    "        prompt += f\"指令: {instruction}\\n\"\n",
    "        prompt += f\"输入:{input}\\n\"\n",
    "        prompt += f\"输出:{output}\\n\"\n",
    "    prompt += f\"###\\n\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def encode_prompt_knowledge():\n",
    "    with open(data_path + '/knowledge.txt', 'r', encoding='utf-8') as file:\n",
    "        knowledge = file.read()\n",
    "    with open(prompt_path + '/prompt_for_knowledge_first.txt', 'r', encoding='utf-8') as file:\n",
    "        prompt_knowledge = file.read()\n",
    "    prompt_knowledge = prompt_knowledge + knowledge\n",
    "    return prompt_knowledge\n",
    "\n",
    "\n",
    "def find_word_in_string(w, s):\n",
    "    return re.compile(r\"\\b({0})\\b\".format(w), flags=re.IGNORECASE).search(s)\n",
    "\n",
    "\n",
    "def process_response(raw_instructions, statistic_report):\n",
    "    instructions = []\n",
    "    input_texts = []\n",
    "    outputs = []\n",
    "    for i, inst in enumerate(raw_instructions):\n",
    "        inst = inst.strip()\n",
    "        statistic_report['Generate in beginning'] += 1\n",
    "        if len(inst.split()) <= 3 or len(inst.split()) > 200:\n",
    "            continue\n",
    "        blacklist = [\n",
    "            \"图片\",\n",
    "            \"图像\",\n",
    "            \"图表\",\n",
    "            \"图\",\n",
    "            \"文件\",\n",
    "            \"地图\",\n",
    "            \"绘制\",\n",
    "            \"绘图\",\n",
    "            \"转到\",\n",
    "            \"视频\",\n",
    "            \"音频\",\n",
    "            \"音乐\",\n",
    "            \"流程图\",\n",
    "            \"代码\",\n",
    "            \"程序\"\n",
    "        ]\n",
    "        if any(find_word_in_string(word, inst) for word in blacklist):\n",
    "            continue\n",
    "        instruction_match = re.search(r'指令(.+)', inst)\n",
    "        input_match = re.search(r'输入(.+)', inst)\n",
    "        output_match = re.search(r'输出(.+)', inst)\n",
    "\n",
    "        if instruction_match and input_match and output_match:\n",
    "            instruction = instruction_match.group(1).strip().lstrip(\":\").lstrip(\"：\")\n",
    "            input_text = input_match.group(1).strip().lstrip(\":\").lstrip(\"：\")\n",
    "            output_text = output_match.group(1).strip().lstrip(\":\").lstrip(\"：\")\n",
    "\n",
    "            if input_text.startswith(\"<\") and input_text != \"<无>\":\n",
    "                continue\n",
    "            if \"比如\" in input_text or \"这\" in input_text:\n",
    "                continue\n",
    "            input_text = \"\" if input_text.lower() == \"<无>\" else input_text\n",
    "            statistic_report['Keep in blocklist and formatting'] += 1\n",
    "            instructions.append(instruction)\n",
    "            input_texts.append(input_text)\n",
    "            outputs.append(output_text)\n",
    "\n",
    "    return {\"instruction\": instructions, \"input_word\": input_texts, \"output\": outputs}\n",
    "\n",
    "\n",
    "def tokenize_chinese(text):\n",
    "    return ' '.join(jieba.lcut(text))\n",
    "def get_bank_token():\n",
    "    all_instructions = [d[\"instruction\"] for d in seed_instruction_data] + (machine_data_df['instruction'].to_list() if machine_data_df.shape[0]!=0 else [])\n",
    "    _all_instruction_tokens = [tokenize_chinese(ins) for ins in all_instructions]\n",
    "    return _all_instruction_tokens\n",
    "\n",
    "def remove_instruction_scoreler_base(all_instruction_tokens, new_instructions, statistic_report):\n",
    "    instructions_keeped = []\n",
    "    rouge = Rouge()\n",
    "    for row_index in range(new_instructions.shape[0]):\n",
    "        specific_ins = new_instructions.loc[row_index, \"instruction\"]\n",
    "        new_instruction_tokens = tokenize_chinese(specific_ins)\n",
    "\n",
    "        with Pool(8) as p:\n",
    "            rouge_scores = p.map(\n",
    "                partial(rouge.get_scores, new_instruction_tokens),\n",
    "                all_instruction_tokens,\n",
    "            )\n",
    "        rouge_scores = [score[0]['rouge-l']['f'] for score in rouge_scores]\n",
    "        \n",
    "        if max(rouge_scores) > 0.8:\n",
    "            continue\n",
    "        \n",
    "        instructions_keeped.append(new_instructions.loc[row_index])\n",
    "        statistic_report[\"Keep in similar check\"] += 1\n",
    "    \n",
    "    return pd.DataFrame(instructions_keeped)\n",
    "\n",
    "\n",
    "def extract_tasks(text):\n",
    "    tasks = []\n",
    "    current_task = \"\"\n",
    "\n",
    "    lines = text.strip().split(\"\\n\")\n",
    "    for line in lines:\n",
    "        if line.startswith(\"任务\") or line.startswith(\"###\") or line.startswith(\"***\") or line.startswith(\"**\") or line.startswith(\"##\"):\n",
    "            if current_task:\n",
    "                tasks.append(current_task.strip())\n",
    "                current_task = \"\"\n",
    "            current_task += line + \"\\n\"\n",
    "        elif line.startswith(\"指令:\") or line.startswith(\"输入:\") or line.startswith(\"输出:\"):\n",
    "            current_task += line + \"\\n\"\n",
    "        elif line.strip():\n",
    "            current_task += line + \"\\n\"\n",
    "\n",
    "    if current_task:\n",
    "        tasks.append(current_task.strip())\n",
    "        \n",
    "    if len(tasks)==0:\n",
    "        print(\"tenpelate can not fit well\")\n",
    "\n",
    "    return tasks"
   ],
   "id": "95915ea1f6abd1f7",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:54:48.140730Z",
     "start_time": "2024-05-25T10:54:48.126736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def getGenerateData_woutKnowledge(client, all_instruction_tokens):\n",
    "    statistic_report = {\"Keep in blocklist and formatting\": 0, \"Generate in beginning\": 0, \"Keep in similar check\": 0}\n",
    "    valid_instruction = []\n",
    "    for t in np.linspace(0.02,0.6,20):\n",
    "        for _ in tqdm(range(int(len(seed_instruction_data) / num_prompt_instructions))):\n",
    "            prompt_instructions = random.sample(seed_instruction_data, num_prompt_instructions)\n",
    "            prompt = encode_prompt(prompt_instructions, '/prompt_Zh.txt')\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF\",\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=t,\n",
    "            )\n",
    "            response_text = completion.choices[0].message.content\n",
    "\n",
    "            # 查找所有符合模式的匹配项\n",
    "            raw_tasks = extract_tasks(response_text)\n",
    "            raw_task_ = process_response(raw_tasks, statistic_report)\n",
    "            new_task_formated_df = pd.DataFrame({\n",
    "                \"instruction\": raw_task_['instruction'],\n",
    "                \"input_word\": raw_task_['input_word'],\n",
    "                \"output\": raw_task_['output']\n",
    "            })\n",
    "        \n",
    "            similar_check_keep = remove_instruction_scoreler_base(all_instruction_tokens, new_task_formated_df,\n",
    "                                                                  statistic_report)\n",
    "\n",
    "            if similar_check_keep.shape[0] != 0:\n",
    "                valid_instruction.append(similar_check_keep)\n",
    "\n",
    "    print(statistic_report)\n",
    "    new_formated_data = pd.concat(valid_instruction)\n",
    "    return new_formated_data\n"
   ],
   "id": "90105f4615ea1e9b",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T11:30:56.048653Z",
     "start_time": "2024-05-25T10:54:48.143729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "instruction_tokens=get_bank_token()\n",
    "new_formated_data_woutKnowledge = getGenerateData_woutKnowledge(client, all_instruction_tokens=instruction_tokens)\n",
    "machine_data_df=pd.concat([machine_data_df, new_formated_data_woutKnowledge], ignore_index=True)\n"
   ],
   "id": "95c9056c55c3ebe3",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Knowledge ",
   "id": "785a8d9680d3424e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T12:46:34.744447Z",
     "start_time": "2024-05-25T12:46:34.716450Z"
    }
   },
   "cell_type": "code",
   "source": "machine_data_df.to_json(data_path + \"/machine_instructions_zh.json\")",
   "id": "a7e80d8ebbbe8c1b",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "360e46017b0e8a4a",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
